import openai
import os
from dotenv import load_dotenv
import json
import folium
from folium.plugins import HeatMap
from geopy.geocoders import Nominatim
from collections import defaultdict
import time
import requests
import urllib.parse
from datetime import datetime
import base64
from branca.element import MacroElement
from jinja2 import Template

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
if not API_KEY:
    raise ValueError("OpenAIã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
openai.api_key = API_KEY

# ========== è¨­å®š ==========
directory = "../../2022-åœ°çƒã®æ­©ãæ–¹æ—…è¡Œè¨˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/data_arukikata/data/domestic/with_schedules/"
base_name = "visited_places_map_emotion_"
extension = ".html"
CACHE_DIR = "results_cache_0707" ### â˜…â˜…â˜… æ©Ÿèƒ½è¿½åŠ : ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª â˜…â˜…â˜…
COLORS = ['blue', 'red', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'lightgray']
WAIT_TIME = 1
MODEL = "gpt-4o"
prefix = '```json'
suffix = '```'

# --- ã‚¿ã‚°ãƒªã‚¹ãƒˆã®å®šç¾© ---
MOVE_TAGS = [
    "å¾’æ­©", "è»Šæ¤…å­", "è‡ªè»¢è»Š(é›»å‹•)", "è‡ªè»¢è»Š(éé›»å‹•)", "ãƒã‚¤ã‚¯", "ãƒã‚¹", "ã‚¿ã‚¯ã‚·ãƒ¼",
    "è‡ªå‹•è»Š(é‹è»¢)", "è‡ªå‹•è»Š(åŒä¹—)"
]
ACTION_TAGS = [
    "é£Ÿäº‹(é£²é…’ã‚ã‚Š)", "é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)", "è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)", "è²·ã„ç‰©(æ—¥ç”¨å“)",
    "è²·ã„ç‰©(ãŠåœŸç”£)", "ã‚¸ãƒ§ã‚®ãƒ³ã‚°", "ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°", "ãƒã‚¤ã‚­ãƒ³ã‚°",
    "æ•£æ­©", "ã‚¹ãƒãƒ¼ãƒ„", "ãƒ¬ã‚¸ãƒ£ãƒ¼", "ãƒ‰ãƒ©ã‚¤ãƒ–",
    "æ™¯è‰²é‘‘è³", "åæ‰€è¦³å…‰", "ä¼‘é¤Šãƒ»ãã¤ã‚ã", "ä»•äº‹",
    "ä»‹è­·ãƒ»çœ‹è­·", "è‚²å…", "é€šé™¢ãƒ»ç™‚é¤Š"
]

# --- ã‚¢ã‚¤ã‚³ãƒ³ç”»åƒé–¢é€£ã®è¨­å®š ---
TAG_TO_IMAGE = {
    # ç§»å‹•é–¢é€£
    "å¾’æ­©": "images/icon_01_å¾’æ­©_stop.png",
    "è»Šæ¤…å­": "images/icon_02_è»Šæ¤…å­_stop.png",
    "è‡ªè»¢è»Š(é›»å‹•)": "images/icon_03_è‡ªè»¢è»Š(é›»å‹•)_stop.png",
    "è‡ªè»¢è»Š(éé›»å‹•)": "images/icon_04_è‡ªè»¢è»Š(éé›»å‹•)_stop.png",
    "ãƒã‚¤ã‚¯": "images/icon_05_ãƒã‚¤ã‚¯_stop.png",
    "ãƒã‚¹": "images/icon_06_ãƒã‚¹_stop.png",
    "ã‚¿ã‚¯ã‚·ãƒ¼": "images/icon_07_ã‚¿ã‚¯ã‚·ãƒ¼_stop.png",
    "è‡ªå‹•è»Š(é‹è»¢)": "images/icon_08_è‡ªå‹•è»Š(é‹è»¢)_stop.png",
    "è‡ªå‹•è»Š(åŒä¹—)": "images/icon_09_è‡ªå‹•è»Š(åŒä¹—)_stop.png",
    # é£Ÿäº‹é–¢é€£
    "é£Ÿäº‹(é£²é…’ã‚ã‚Š)": "images/icon_10_é£²é…’ã‚ã‚Š_stop.png",
    "é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)": "images/icon_11_é£²é…’ãªã—ãƒ»ä¸æ˜_stop.png",
    "è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)": "images/icon_12_è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)_stop.png",
    # è¡Œå‹•é–¢é€£
    "è²·ã„ç‰©(æ—¥ç”¨å“)": "images/icon_13_æ—¥ç”¨å“_stop.png",
    "è²·ã„ç‰©(ãŠåœŸç”£)": "images/icon_14_ãŠåœŸç”£_stop.png",
    "ã‚¸ãƒ§ã‚®ãƒ³ã‚°": "images/icon_15_ã‚¸ãƒ§ã‚®ãƒ³ã‚°_stop.png",
    "ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°": "images/icon_16_ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°_stop.png",
    "ãƒã‚¤ã‚­ãƒ³ã‚°": "images/icon_17_ãƒã‚¤ã‚­ãƒ³ã‚¯ã‚™_stop.png",
    "æ•£æ­©": "images/icon_18_æ•£æ­©_stop.png",
    "ã‚¹ãƒãƒ¼ãƒ„": "images/icon_19_ã‚¹ãƒ›ã‚šãƒ¼ãƒ„_stop.png",
    "ãƒ¬ã‚¸ãƒ£ãƒ¼": "images/icon_20_ãƒ¬ã‚·ã‚™ãƒ£ãƒ¼_stop.png",
    "ãƒ‰ãƒ©ã‚¤ãƒ–": "images/icon_21_ãƒˆã‚™ãƒ©ã‚¤ãƒ•ã‚™_stop.png",
    "æ™¯è‰²é‘‘è³": "images/icon_22_æ™¯è‰²é‘‘è³_stop.png",
    "åæ‰€è¦³å…‰": "images/icon_23_åæ‰€è¦³å…‰_stop.png",
    "ä¼‘é¤Šãƒ»ãã¤ã‚ã": "images/icon_24_ä¼‘é¤Šãƒ»ãã¤ã‚ãã‚™_stop.png",
    # ãã®ä»–
    "ä»•äº‹": "images/icon_25_ä»•äº‹_stop.png",
    "ä»‹è­·ãƒ»çœ‹è­·": "images/icon_26_ä»‹è­·ãƒ»çœ‹è­·_stop.png",
    "è‚²å…": "images/icon_27_è‚²å…_stop.png",
    "é€šé™¢ãƒ»ç™‚é¤Š": "images/icon_28_é€šé™¢ãƒ»ç™‚é¤Š_stop.png"
}
TAG_PRIORITY = [
    "é£Ÿäº‹(é£²é…’ã‚ã‚Š)", "é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)", "è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)", "è²·ã„ç‰©(ãŠåœŸç”£)", "åæ‰€è¦³å…‰",
    "ãƒã‚¹", "ã‚¿ã‚¯ã‚·ãƒ¼", "è‡ªå‹•è»Š(é‹è»¢)", "è‡ªå‹•è»Š(åŒä¹—)", "å¾’æ­©",
    "è²·ã„ç‰©(æ—¥ç”¨å“)", "ã‚¸ãƒ§ã‚®ãƒ³ã‚°", "ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°", "ãƒã‚¤ã‚­ãƒ³ã‚°", "æ•£æ­©", 
    "ã‚¹ãƒãƒ¼ãƒ„", "ãƒ¬ã‚¸ãƒ£ãƒ¼", "ãƒ‰ãƒ©ã‚¤ãƒ–", "æ™¯è‰²é‘‘è³", "ä¼‘é¤Šãƒ»ãã¤ã‚ã", 
    "ä»•äº‹", "ä»‹è­·ãƒ»çœ‹è­·", "è‚²å…", "é€šé™¢ãƒ»ç™‚é¤Š"
]
DEFAULT_ICON_IMAGE = "images/default.png"
TAG_TO_GIF = {
    # ç§»å‹•é–¢é€£
    "å¾’æ­©": "gifs/anim_icon_01_å¾’æ­©.gif",
    "è»Šæ¤…å­": "gifs/anim_icon_02_è»Šæ¤…å­.gif",
    "è‡ªè»¢è»Š(é›»å‹•)": "gifs/anim_icon_03_è‡ªè»¢è»Š(é›»å‹•).gif",
    "è‡ªè»¢è»Š(éé›»å‹•)": "gifs/anim_icon_04_è‡ªè»¢è»Š(éé›»å‹•).gif",
    "ãƒã‚¤ã‚¯": "gifs/anim_icon_05_ãƒã‚¤ã‚¯.gif",
    "ãƒã‚¹": "gifs/anim_icon_06_ãƒã‚¹.gif",
    "ã‚¿ã‚¯ã‚·ãƒ¼": "gifs/anim_icon_07_ã‚¿ã‚¯ã‚·ãƒ¼.gif",
    "è‡ªå‹•è»Š(é‹è»¢)": "gifs/anim_icon_08_è‡ªå‹•è»Š(é‹è»¢).gif",
    "è‡ªå‹•è»Š(åŒä¹—)": "gifs/anim_icon_09_è‡ªå‹•è»Š(åŒä¹—).gif",
    # é£Ÿäº‹é–¢é€£
    "é£Ÿäº‹(é£²é…’ã‚ã‚Š)": "gifs/anim_icon_10_é£²é…’ã‚ã‚Š.gif",
    "é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)": "gifs/anim_icon_11_é£²é…’ãªã—ãƒ»ä¸æ˜.gif",
    "è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)": "gifs/anim_icon_12_è»½é£Ÿï¼ˆã‚«ãƒ•ã‚§ãªã¨ã‚™ï¼‰.gif",
    # è¡Œå‹•é–¢é€£
    "è²·ã„ç‰©(æ—¥ç”¨å“)": "gifs/anim_icon_13_æ—¥ç”¨å“.gif",
    "è²·ã„ç‰©(ãŠåœŸç”£)": "gifs/anim_icon_14_ãŠåœŸç”£.gif",
    "ã‚¸ãƒ§ã‚®ãƒ³ã‚°": "gifs/anim_icon_15_ã‚¸ãƒ§ã‚®ãƒ³ã‚°.gif",
    "ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°": "gifs/anim_icon_16_ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°.gif",
    "ãƒã‚¤ã‚­ãƒ³ã‚°": "gifs/anim_icon_17_ãƒã‚¤ã‚­ãƒ³ã‚¯ã‚™.gif",
    "æ•£æ­©": "gifs/anim_icon_18_æ•£æ­©.gif",
    "ã‚¹ãƒãƒ¼ãƒ„": "gifs/anim_icon_19_ã‚¹ãƒ›ã‚šãƒ¼ãƒ„.gif",
    "ãƒ¬ã‚¸ãƒ£ãƒ¼": "gifs/anim_icon_20_ãƒ¬ã‚·ã‚™ãƒ£ãƒ¼.gif",
    "ãƒ‰ãƒ©ã‚¤ãƒ–": "gifs/anim_icon_21_ãƒˆã‚™ãƒ©ã‚¤ãƒ•ã‚™.gif",
    "æ™¯è‰²é‘‘è³": "gifs/anim_icon_22_æ™¯è‰²é‘‘è³.gif",
    "åæ‰€è¦³å…‰": "gifs/anim_icon_23_åæ‰€è¦³å…‰.gif",
    "ä¼‘é¤Šãƒ»ãã¤ã‚ã": "gifs/anim_icon_24_ä¼‘é¤Šãƒ»ãã¤ã‚ãã‚™.gif",
    # ãã®ä»–
    "ä»•äº‹": "gifs/anim_icon_25_ä»•äº‹.gif",
    "ä»‹è­·ãƒ»çœ‹è­·": "gifs/anim_icon_26_ä»‹è­·ãƒ»çœ‹è­·.gif",
    "è‚²å…": "gifs/anim_icon_27_è‚²å….gif",
    "é€šé™¢ãƒ»ç™‚é¤Š": "gifs/anim_icon_28_é€šé™¢ãƒ»ç™‚é¤Š.gif"
}
# ========================================================

geolocator = Nominatim(user_agent="travel-map-final")

# (æ—¢å­˜ã® map_emotion_and_routes é–¢æ•°ã¨ LayerToggleButtons ã‚¯ãƒ©ã‚¹ã¯å‰Šé™¤ã—ã¦ãã ã•ã„)

### â˜…â˜…â˜… è»Œè·¡ã®ã¿ã®åœ°å›³ã‚’ç”Ÿæˆã™ã‚‹æ–°ã—ã„é–¢æ•° â˜…â˜…â˜…
def map_traces_only(travels_data, output_html):
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—…è¡Œè¨˜ã”ã¨ã®è»Œè·¡ï¼ˆç·šï¼‰ã®ã¿ã‚’æç”»ã—ãŸåœ°å›³ã‚’ç”Ÿæˆã™ã‚‹"""
    if not travels_data:
        print("[ERROR] åœ°å›³ã«æç”»ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # åœ°å›³ã®ä¸­å¿ƒã‚’æœ€åˆã®æ—…è¡Œè¨˜ã®é–‹å§‹åœ°ç‚¹ã«è¨­å®š
    try:
        first_travel = travels_data[0]['places'][0]
        start_coords = (first_travel['latitude'], first_travel['longitude'])
        m = folium.Map(location=start_coords, zoom_start=10)
    except (IndexError, KeyError):
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æ±äº¬é§…ã‚’ä¸­å¿ƒã«ã™ã‚‹
        m = folium.Map(location=[35.6812, 139.7671], zoom_start=10)

    # å„æ—…è¡Œè¨˜ã®è»Œè·¡ã‚’åœ°å›³ã«è¿½åŠ 
    for travel in travels_data:
        file_num = travel["file_num"]
        places = travel["places"]
        color = travel["color"]

        # è»Œè·¡ã‚’æç”»ã™ã‚‹ãŸã‚ã®åº§æ¨™ãƒªã‚¹ãƒˆ
        locations = [(p['latitude'], p['longitude']) for p in places if p.get('latitude') and p.get('longitude')]

        # è»Œè·¡ã‚’æ ¼ç´ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆï¼ˆãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ç”¨ï¼‰
        trace_group = folium.FeatureGroup(name=f"æ—…è¡Œè¨˜ãƒ«ãƒ¼ãƒˆ: {file_num}", show=True)

        # è¨ªå•åœ°ãŒ2ç®‡æ‰€ä»¥ä¸Šã‚ã‚‹å ´åˆã®ã¿ç·šã‚’æç”»
        if len(locations) > 1:
            folium.PolyLine(
                locations,
                color=color,
                weight=5,
                opacity=0.8
            ).add_to(trace_group)
        
        trace_group.add_to(m)

    # ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ï¼ˆå„è»Œè·¡ã®è¡¨ç¤º/éè¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆï¼‰ã‚’è¿½åŠ 
    folium.LayerControl().add_to(m)

    m.save(output_html)
    print(f"\nğŸŒ è»Œè·¡ã®ã¿ã®åœ°å›³ã‚’ {output_html} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
# --- åº§æ¨™å–å¾—ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ»åˆ†æé–¢æ•°ç¾¤ ---
# (geocode_gsi, geocode_place, extract_places, get_visit_hint, analyze_experience, get_image_as_base64 ã®ã‚³ãƒ¼ãƒ‰ã¯çœç•¥)
def get_image_as_base64(file_path):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€HTMLåŸ‹ã‚è¾¼ã¿ç”¨ã®Base64æ–‡å­—åˆ—ã‚’è¿”ã™"""
    try:
        with open(file_path, "rb") as f:
            encoded_string = base64.b64encode(f.read()).decode("utf-8")
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«å¿œã˜ã¦MIMEã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š (ã“ã“ã§ã¯gifã«å›ºå®š)
        return f"data:image/gif;base64,{encoded_string}"
    except FileNotFoundError:
        print(f"[WARNING] ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return None
def geocode_gsi(name):
    """å›½åœŸåœ°ç†é™¢APIã‚’ä½¿ã£ã¦åœ°åã®ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã™ã‚‹"""
    try:
        query = urllib.parse.quote(name)
        url = f"https://msearch.gsi.go.jp/address-search/AddressSearch?q={query}"
        print(f"ğŸ—ºï¸ Geocoding (GSI): '{name}'...")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data and isinstance(data, list):
            coords = data[0]['geometry']['coordinates']
            lon, lat = coords[0], coords[1]
            return lat, lon
    except: return None

def geocode_place(name, region_hint):
    """Geopyã‚’ä½¿ã£ã¦åœ°åã®ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã™ã‚‹"""
    try:
        query = f"{name}, {region_hint}"
        print(f"ğŸ—ºï¸ Geocoding (Geopy): '{query}'...")
        location = geolocator.geocode(query, timeout=10)
        time.sleep(WAIT_TIME)
        if location:
            return location.latitude, location.longitude
    except: return None

def extract_places(texts, region_hint):
    """GPTã‚’ä½¿ã£ã¦æ—…è¡Œè¨˜ã‹ã‚‰åœ°åã¨ä½“é¨“ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åº§æ¨™ã‚’æŠ½å‡ºã™ã‚‹"""
    print("ğŸ“Œ è¨ªå•åœ°æŠ½å‡ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’[å‡ºåŠ›ä¾‹ä»˜ã]ã®å®Œå…¨ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å®Ÿè¡Œã—ã¾ã™...")
    prompt = f"""
    ä»¥ä¸‹ã®æ—…è¡Œè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è¨ªã‚ŒãŸå ´æ‰€ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    å‡ºåŠ›ã«ã¯ "place"ï¼ˆåœ°åï¼‰ã€"latitude"ï¼ˆç·¯åº¦ï¼‰ã€"longitude"ï¼ˆçµŒåº¦ï¼‰ã€"experience"ï¼ˆãã®å ´æ‰€ã§ã®çµŒé¨“ï¼‰ã€"reasoning"ï¼ˆãã®åº§æ¨™ã ã¨æ¨å®šã—ãŸç†ç”±ï¼‰ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
    ç·¯åº¦çµŒåº¦ã¯ã€æ—¥æœ¬ã®ã€Œ{region_hint}ã€å‘¨è¾ºã®åœ°ç†æƒ…å ±ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æ–‡è„ˆï¼ˆä¾‹ï¼šã€Œã€‡ã€‡é§…ã‹ã‚‰å¾’æ­©5åˆ†ã€ã€Œâ–³â–³ã®éš£ã€ãªã©ï¼‰ã‚’æœ€å¤§é™è€ƒæ…®ã—ã¦ã€éå¸¸ã«é«˜ã„ç²¾åº¦ã§æ¨å®šã—ã¦ãã ã•ã„ã€‚
    å‡ºåŠ›ã¯**çµ¶å¯¾ã«JSONå½¢å¼ã®ãƒªã‚¹ãƒˆ**ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚
    ä¾‹:
    [
        {{"place": "è‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«", "latitude": 36.6222, "longitude": 138.5964, "experience": "è‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«åˆ°ç€ã—ã¾ã—ãŸã€‚", "reasoning": "ãƒ†ã‚­ã‚¹ãƒˆã«ã€Œè‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«åˆ°ç€ã€ã¨æ˜è¨˜ã•ã‚Œã¦ãŠã‚Šã€ãã®åç§°ã§ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸçµæœã§ã™ã€‚"}},
        {{"place": "æ¹¯ç•‘", "latitude": 36.6214, "longitude": 138.5968, "experience": "æ¹¯ç•‘ã‚’æ•£ç­–ã—ã¾ã—ãŸã€‚", "reasoning": "è‰æ´¥æ¸©æ³‰ã®ä¸­å¿ƒçš„ãªè¦³å…‰ã‚¹ãƒãƒƒãƒˆã§ã‚ã‚Šã€æ—…è¡Œè¨˜ã®æ–‡è„ˆã‹ã‚‰è‰æ´¥æ¸©æ³‰ã¸ã®è¨ªå•ãŒæ˜ã‚‰ã‹ãªãŸã‚ã€æ¹¯ç•‘ã®åº§æ¨™ã‚’æŒ‡å®šã—ã¾ã—ãŸã€‚"}}
    ]
    ãƒ†ã‚­ã‚¹ãƒˆ: {texts}
    """
    response = openai.ChatCompletion.create(model=MODEL, messages=[{"role": "system", "content": f"ã‚ãªãŸã¯æ—…è¡Œè¨˜ã‹ã‚‰è¨ªå•åœ°ã‚’æ­£ç¢ºã«æŠ½å‡ºã™ã‚‹å„ªç§€ãªæ—…è¡Œã‚¬ã‚¤ãƒ‰ã§ã™ã€‚æ—¥æœ¬ã®ã€Œ{region_hint}ã€ã«é–¢ã™ã‚‹åœ°ç†ã«è©³ã—ã„ã§ã™ã€‚"}, {"role": "user", "content": prompt}], temperature=0.5)
    textforarukikata = response.choices[0].message.content.strip()
    if prefix in textforarukikata: textforarukikata = textforarukikata.split(prefix, 1)[1]
    if suffix in textforarukikata: textforarukikata = textforarukikata.rsplit(suffix, 1)[0]
    try:
        result = json.loads(textforarukikata.strip())
        if isinstance(result, list) and all(isinstance(item, dict) for item in result):
            for item in result:
                item['latitude'] = float(item.get('latitude', 0.0))
                item['longitude'] = float(item.get('longitude', 0.0))
            return result
        else: return []
    except: return []

def get_visit_hint(visited_places_text):
    if not visited_places_text.strip(): return "æ—¥æœ¬"
    messages = [{"role": "system", "content": "éƒ½é“åºœçœŒåã‚’ç­”ãˆã‚‹ã¨ãã¯ï¼ŒçœŒåã®ã¿ã‚’ç­”ãˆã¦ãã ã•ã„ï¼"}, {"role": "user", "content": f"ä»¥ä¸‹ã®æ—…è¡Œè¨˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç­†è€…ãŒè¨ªã‚ŒãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹éƒ½é“åºœçœŒã‚’1ã¤ã ã‘ç­”ãˆã¦ãã ã•ã„ï¼ãŸã ã—ï¼Œç‰¹å®šã®èªå¥ã«æ‹˜ã‚‰ãšã«æ—…è¡Œè¨˜å…¨ä½“ã‹ã‚‰ç·åˆçš„ã«åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼\n\n{visited_places_text}"}]
    try:
        response = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=messages, temperature=0.2)
        return response.choices[0].message.content.strip()
    except: return "æ—¥æœ¬"
    
### â˜…â˜…â˜… æ©Ÿèƒ½å¤‰æ›´ (1/2): exceptãƒ–ãƒ­ãƒƒã‚¯ã‚’æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³å½¢å¼ã«ä¿®æ­£ â˜…â˜…â˜…
def analyze_experience(text, move_tags_list, action_tags_list):
    """1å›ã®APIã‚³ãƒ¼ãƒ«ã§æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨ã‚¿ã‚°ã‚’åŒæ™‚ã«æŠ½å‡ºã™ã‚‹"""
    if not text or not text.strip():
        return {"emotion_score": 0.5, "tags": []}

    print(f"âš¡ï¸ Analyzing (Emotion + Tags) for: '{text[:40]}...'")
    
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€æ—…è¡Œä¸­ã®ã‚ã‚‹å ´æ‰€ã§ã®çµŒé¨“ã‚’è¨˜è¿°ã—ãŸã‚‚ã®ã§ã™ã€‚
    ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€ä»¥ä¸‹ã®3ã¤ã®ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

    1.  **æ„Ÿæƒ…åˆ†æ**: ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã®æ„Ÿæƒ…ã‚’0.0ï¼ˆéå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆéå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®æ•°å€¤ï¼ˆã‚¹ã‚³ã‚¢ï¼‰ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªæ„Ÿæƒ…ã¯0.5ã¨ã—ã¾ã™ã€‚
    2.  **ç§»å‹•ã‚¿ã‚°æŠ½å‡º**: æç¤ºã•ã‚ŒãŸã€Œç§»å‹•æ‰‹æ®µã€ã‚¿ã‚°ãƒªã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã€ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚¿ã‚°ã‚’ã™ã¹ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚
    3.  **è¡Œå‹•ã‚¿ã‚°æŠ½å‡º**: æç¤ºã•ã‚ŒãŸã€Œè¡Œå‹•ã€ã‚¿ã‚°ãƒªã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã€ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚¿ã‚°ã‚’ã™ã¹ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚

    é–¢é€£æ€§ã®é«˜ã„ã‚¿ã‚°ãŒä¸€ã¤ã‚‚ãªã‘ã‚Œã°ã€ç©ºã®ãƒªã‚¹ãƒˆ `[]` ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    å‡ºåŠ›ã¯å¿…ãšã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’æŒã¤JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚
    - `emotion_score`: æ•°å€¤
    - `move_tags`: æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ
    - `action_tags`: æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ

    ä¾‹:
    {{
        "emotion_score": 0.85,
        "move_tags": ["ãƒã‚¹", "å¾’æ­©"],
        "action_tags": ["é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)", "æ™¯è‰²é‘‘è³"]
    }}
    ---
    ã€Œç§»å‹•æ‰‹æ®µã€ã‚¿ã‚°ãƒªã‚¹ãƒˆ: {move_tags_list}
    ---
    ã€Œè¡Œå‹•ã€ã‚¿ã‚°ãƒªã‚¹ãƒˆ: {action_tags_list}
    ---
    ãƒ†ã‚­ã‚¹ãƒˆ: ã€Œ{text}ã€
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤šè§’çš„ã«åˆ†æã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨è¤‡æ•°ç¨®é¡ã®ã‚¿ã‚°ã‚’æ­£ç¢ºã«å‡ºåŠ›ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        result = json.loads(response.choices[0].message.content)
        
        score = result.get("emotion_score", 0.5)
        move_tags = result.get("move_tags", [])
        action_tags = result.get("action_tags", [])
        all_tags = move_tags + action_tags

        return {"emotion_score": score, "tags": all_tags}
    
    # æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³(v0.x)ã®openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”¨ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    except openai.error.AuthenticationError as e:
        print(f"[FATAL ERROR] OpenAIèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        raise # ã‚¨ãƒ©ãƒ¼ã‚’å†ç™ºç”Ÿã•ã›ã€mainã®try-exceptã§æ•æ‰ã™ã‚‹
    except Exception as e:
        print(f"[ERROR] çµ±åˆåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {"emotion_score": 0.5, "tags": []}



### â˜…â˜…â˜… æ©Ÿèƒ½å¤‰æ›´ (2/2): exceptãƒ–ãƒ­ãƒƒã‚¯ã‚’æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³å½¢å¼ã«ä¿®æ­£ â˜…â˜…â˜…
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)
        print(f"INFO: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {CACHE_DIR}")

    input_file_path = input('ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ãŒè¨˜è¼‰ã•ã‚ŒãŸ.txtãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ')
    try:
        with open(input_file_path, 'r', encoding='utf-8') as f: content = f.read()
        file_nums_raw = content.strip().split(',')
        file_nums = [num.strip() for num in file_nums_raw if num.strip()] 
        if not file_nums: print("[ERROR] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return
        print(f"INFO: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(file_nums)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except FileNotFoundError: print(f"[ERROR] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file_path}"); return
    except Exception as e: print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return

    all_travels_data = []
    try:
        for i, file_num in enumerate(file_nums):
            cache_path = os.path.join(CACHE_DIR, f"{file_num}.json")
            if os.path.exists(cache_path):
                print(f"\nâœ… [{file_num}] ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
                with open(cache_path, 'r', encoding='utf-8') as f:
                    travel_result_data = json.load(f)
                all_travels_data.append(travel_result_data)
                continue

            print(f"\n{'='*20} [{file_num}] ã®å‡¦ç†ã‚’é–‹å§‹ {'='*20}")
            path_journal = f'{directory}{file_num}.tra.json'
            
            if not os.path.exists(path_journal): print(f"[WARNING] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path_journal}"); continue
            try:
                with open(path_journal, "r", encoding="utf-8") as f: travel_data = json.load(f)
            except: print(f"[ERROR] JSONèª­ã¿è¾¼ã¿å¤±æ•—"); continue
            texts = [];
            for entry in travel_data: texts.extend(entry['text'])
            full_text = " ".join(texts)
            if not full_text.strip(): print(f"[WARNING] æ—…è¡Œè¨˜ {file_num} ã«ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); continue
            
            region_hint = get_visit_hint(full_text)
            extracted_places = extract_places(full_text, region_hint)
            if not extracted_places: print(f"[WARNING] æ—…è¡Œè¨˜ {file_num} ã‹ã‚‰è¨ªå•åœ°ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"); continue

            places_with_coords = []
            for place_data in extracted_places:
                place_name = place_data['place']
                coords = geocode_place(place_name, region_hint)
                if not coords:
                    coords = (place_data['latitude'], place_data['longitude'])
                    if coords[0] == 0.0 and coords[1] == 0.0: coords = None
                if not coords:
                    coords = geocode_gsi(place_name)
                if coords:
                    place_data['latitude'] = coords[0]
                    place_data['longitude'] = coords[1]
                    places_with_coords.append(place_data)
                else:
                    print(f"[!] å…¨ã¦ã®ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: {place_name}")

            grouped_experiences = defaultdict(list)
            for p in places_with_coords: grouped_experiences[p['place']].append(p['experience'])
            
            place_analysis_results = {}
            for place, experiences in grouped_experiences.items():
                analysis_result = analyze_experience(" ".join(experiences), MOVE_TAGS, ACTION_TAGS)
                place_analysis_results[place] = analysis_result

            for p in places_with_coords:
                analysis = place_analysis_results.get(p['place'], {"emotion_score": 0.5, "tags": []})
                p['emotion_score'] = analysis['emotion_score']
                p['tags'] = analysis['tags']
            
            final_travel_data = {
                "file_num": file_num, "places": places_with_coords,
                "color": COLORS[i % len(COLORS)], "region_hint": region_hint 
            }
            all_travels_data.append(final_travel_data)

            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(final_travel_data, f, ensure_ascii=False, indent=4)
            print(f"âœ… [{file_num}] ã®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            
            print(f"ğŸ“Œ å‡¦ç†å®Œäº† ({file_num}): {len(places_with_coords)}ä»¶ã®è¨ªå•åœ°ã‚’åœ°å›³ã«è¿½åŠ ã—ã¾ã™ã€‚")

    # æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³(v0.x)ã®openaiãƒ©ã‚¤ãƒ–ãƒ©ãƒªç”¨ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    except openai.error.AuthenticationError as e:
        print("\n" + "="*50)
        print(f"[FATAL ERROR] OpenAIã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        print("APIã‚­ãƒ¼ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã€ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒä¸è¶³ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("å‡¦ç†ã‚’ä¸­æ–­ã—ã€ç¾åœ¨ã¾ã§ã®çµæœã§åœ°å›³ã‚’ç”Ÿæˆã—ã¾ã™...")
        print("="*50 + "\n")
    except Exception as e:
        print(f"\n[FATAL ERROR] äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™: {e}")
        print("ç¾åœ¨ã¾ã§ã®çµæœã§åœ°å›³ã‚’ç”Ÿæˆã—ã¾ã™...")

    base_name = "trace_only_map_"

    if all_travels_data:
        if len(all_travels_data) >= 4:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{base_name}{timestamp}{extension}"
        else:
            processed_file_nums = [str(t['file_num']) for t in all_travels_data]
            output_filename = f"{base_name}{'_'.join(processed_file_nums)}{extension}"
            
        print(f"\nğŸ—ºï¸ {len(all_travels_data)}ä»¶ã®æ—…è¡Œè¨˜ãƒ‡ãƒ¼ã‚¿ã§è»Œè·¡ã®ã¿ã®åœ°å›³ã‚’ç”Ÿæˆã—ã¾ã™...")
        # â˜…â˜…â˜… å¤‰æ›´ç‚¹ 2/2: å‘¼ã³å‡ºã™é–¢æ•°ã‚’æ–°ã—ã„ã‚‚ã®ã«å¤‰æ›´ â˜…â˜…â˜…
        map_traces_only(all_travels_data, output_filename)
    else:
        print("\nåœ°å›³ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


if __name__ == '__main__':
    main()
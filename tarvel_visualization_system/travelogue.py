import openai
import os
from dotenv import load_dotenv
import json
import folium
from folium.plugins import HeatMap
from geopy.geocoders import Nominatim
from collections import defaultdict
import time
import requests
import urllib.parse
from datetime import datetime

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()
API_KEY = os.getenv('OPENAI_API_KEY')
if not API_KEY:
    raise ValueError("OpenAIã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
openai.api_key = API_KEY

# ========== è¨­å®š ==========
directory = "../../2022-åœ°çƒã®æ­©ãæ–¹æ—…è¡Œè¨˜ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ/data_arukikata/data/domestic/with_schedules/"
base_name = "visited_places_map_emotion_"
extension = ".html"
COLORS = ['blue', 'red', 'green', 'purple', 'orange', 'darkred', 'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue', 'lightgray']
WAIT_TIME = 1
MODEL = "gpt-4o"
prefix = '```json'
suffix = '```'
# ==========================

### â˜…â˜…â˜… æ©Ÿèƒ½è¿½åŠ : ã‚¿ã‚°ãƒªã‚¹ãƒˆã®å®šç¾© â˜…â˜…â˜…
MOVE_TAGS = [
    "å¾’æ­©", "è»Šæ¤…å­", "è‡ªè»¢è»Š(é›»å‹•)", "è‡ªè»¢è»Š(éé›»å‹•)", "ãƒã‚¤ã‚¯", "ãƒã‚¹", "ã‚¿ã‚¯ã‚·ãƒ¼", 
    "è‡ªå‹•è»Š(é‹è»¢)", "è‡ªå‹•è»Š(åŒä¹—)"
]
ACTION_TAGS = [
    "é£Ÿäº‹(é£²é…’ã‚ã‚Š)", "é£Ÿäº‹(é£²é…’ãªã—ãƒ»ä¸æ˜)", "è»½é£Ÿ(ã‚«ãƒ•ã‚§ãªã©)", "è²·ã„ç‰©(æ—¥ç”¨å“)", 
    "è²·ã„ç‰©(ãŠåœŸç”£)", "å¨¯æ¥½(ã‚¸ãƒ§ã‚®ãƒ³ã‚°)", "å¨¯æ¥½(ã‚¦ã‚©ãƒ¼ã‚­ãƒ³ã‚°)", "å¨¯æ¥½(ãƒã‚¤ã‚­ãƒ³ã‚°)", 
    "å¨¯æ¥½(æ•£æ­©)", "å¨¯æ¥½(ã‚¹ãƒãƒ¼ãƒ„)", "å¨¯æ¥½(ãƒ¬ã‚¸ãƒ£ãƒ¼)", "å¨¯æ¥½(ãƒ‰ãƒ©ã‚¤ãƒ–)", 
    "å¨¯æ¥½(æ™¯è‰²é‘‘è³)", "å¨¯æ¥½(åæ‰€è¦³å…‰)", "å¨¯æ¥½(ä¼‘é¤Šãƒ»ãã¤ã‚ã)", "ãã®ä»–(ä»•äº‹)", 
    "ãã®ä»–(ä»‹è­·ãƒ»çœ‹è­·)", "ãã®ä»–(è‚²å…)", "ãã®ä»–(é€šé™¢ãƒ»ç™‚é¤Š)"
]
# =======================================

geolocator = Nominatim(user_agent="travel-map-final")

# --- åº§æ¨™å–å¾—ãƒ»ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ»æ„Ÿæƒ…åˆ†æã®å„é–¢æ•° ---
def geocode_gsi(name):
    """ã€æœ€çµ‚æ‰‹æ®µã€‘å›½åœŸåœ°ç†é™¢APIã‚’ä½¿ã£ã¦åœ°åã®ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã™ã‚‹"""
    try:
        query = urllib.parse.quote(name)
        url = f"https://msearch.gsi.go.jp/address-search/AddressSearch?q={query}"
        print(f"ğŸ—ºï¸ Geocoding (GSI): '{name}'...")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data and isinstance(data, list):
            coords = data[0]['geometry']['coordinates']
            lon, lat = coords[0], coords[1]
            return lat, lon
    except: return None

def geocode_place(name, region_hint):
    """ã€æœ€å„ªå…ˆã€‘Geopyã‚’ä½¿ã£ã¦åœ°åã®ç·¯åº¦çµŒåº¦ã‚’å–å¾—ã™ã‚‹"""
    try:
        query = f"{name}, {region_hint}"
        print(f"ğŸ—ºï¸ Geocoding (Geopy): '{query}'...")
        location = geolocator.geocode(query, timeout=10)
        time.sleep(WAIT_TIME)
        if location:
            return location.latitude, location.longitude
    except: return None

def extract_places(texts, region_hint):
    """GPTã‚’ä½¿ã£ã¦æ—…è¡Œè¨˜ã‹ã‚‰åœ°åã¨ä½“é¨“ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åº§æ¨™ã‚’æŠ½å‡ºã™ã‚‹"""
    print("ğŸ“Œ è¨ªå•åœ°æŠ½å‡ºã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’[å‡ºåŠ›ä¾‹ä»˜ã]ã®å®Œå…¨ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å®Ÿè¡Œã—ã¾ã™...")
    prompt = f"""
    ä»¥ä¸‹ã®æ—…è¡Œè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è¨ªã‚ŒãŸå ´æ‰€ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    å‡ºåŠ›ã«ã¯ "place"ï¼ˆåœ°åï¼‰ã€"latitude"ï¼ˆç·¯åº¦ï¼‰ã€"longitude"ï¼ˆçµŒåº¦ï¼‰ã€"experience"ï¼ˆãã®å ´æ‰€ã§ã®çµŒé¨“ï¼‰ã€"reasoning"ï¼ˆãã®åº§æ¨™ã ã¨æ¨å®šã—ãŸç†ç”±ï¼‰ã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
    ç·¯åº¦çµŒåº¦ã¯ã€æ—¥æœ¬ã®ã€Œ{region_hint}ã€å‘¨è¾ºã®åœ°ç†æƒ…å ±ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆå†…ã®æ–‡è„ˆï¼ˆä¾‹ï¼šã€Œã€‡ã€‡é§…ã‹ã‚‰å¾’æ­©5åˆ†ã€ã€Œâ–³â–³ã®éš£ã€ãªã©ï¼‰ã‚’æœ€å¤§é™è€ƒæ…®ã—ã¦ã€éå¸¸ã«é«˜ã„ç²¾åº¦ã§æ¨å®šã—ã¦ãã ã•ã„ã€‚
    å‡ºåŠ›ã¯**çµ¶å¯¾ã«JSONå½¢å¼ã®ãƒªã‚¹ãƒˆ**ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚
    ä¾‹:
    [
        {{"place": "è‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«", "latitude": 36.6222, "longitude": 138.5964, "experience": "è‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«åˆ°ç€ã—ã¾ã—ãŸã€‚", "reasoning": "ãƒ†ã‚­ã‚¹ãƒˆã«ã€Œè‰æ´¥æ¸©æ³‰ãƒã‚¹ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«åˆ°ç€ã€ã¨æ˜è¨˜ã•ã‚Œã¦ãŠã‚Šã€ãã®åç§°ã§ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ãŸçµæœã§ã™ã€‚"}},
        {{"place": "æ¹¯ç•‘", "latitude": 36.6214, "longitude": 138.5968, "experience": "æ¹¯ç•‘ã‚’æ•£ç­–ã—ã¾ã—ãŸã€‚", "reasoning": "è‰æ´¥æ¸©æ³‰ã®ä¸­å¿ƒçš„ãªè¦³å…‰ã‚¹ãƒãƒƒãƒˆã§ã‚ã‚Šã€æ—…è¡Œè¨˜ã®æ–‡è„ˆã‹ã‚‰è‰æ´¥æ¸©æ³‰ã¸ã®è¨ªå•ãŒæ˜ã‚‰ã‹ãªãŸã‚ã€æ¹¯ç•‘ã®åº§æ¨™ã‚’æŒ‡å®šã—ã¾ã—ãŸã€‚"}}
    ]
    ãƒ†ã‚­ã‚¹ãƒˆ: {texts}
    """
    response = openai.ChatCompletion.create(model=MODEL, messages=[{"role": "system", "content": f"ã‚ãªãŸã¯æ—…è¡Œè¨˜ã‹ã‚‰è¨ªå•åœ°ã‚’æ­£ç¢ºã«æŠ½å‡ºã™ã‚‹å„ªç§€ãªæ—…è¡Œã‚¬ã‚¤ãƒ‰ã§ã™ã€‚æ—¥æœ¬ã®ã€Œ{region_hint}ã€ã«é–¢ã™ã‚‹åœ°ç†ã«è©³ã—ã„ã§ã™ã€‚"}, {"role": "user", "content": prompt}], temperature=0.5)
    textforarukikata = response.choices[0].message.content.strip()
    if prefix in textforarukikata: textforarukikata = textforarukikata.split(prefix, 1)[1]
    if suffix in textforarukikata: textforarukikata = textforarukikata.rsplit(suffix, 1)[0]
    try:
        result = json.loads(textforarukikata.strip())
        if isinstance(result, list) and all(isinstance(item, dict) for item in result):
            for item in result:
                item['latitude'] = float(item.get('latitude', 0.0))
                item['longitude'] = float(item.get('longitude', 0.0))
            return result
        else: return []
    except: return []

def get_visit_hint(visited_places_text):
    if not visited_places_text.strip(): return "æ—¥æœ¬"
    messages = [{"role": "system", "content": "éƒ½é“åºœçœŒåã‚’ç­”ãˆã‚‹ã¨ãã¯ï¼ŒçœŒåã®ã¿ã‚’ç­”ãˆã¦ãã ã•ã„ï¼"}, {"role": "user", "content": f"ä»¥ä¸‹ã®æ—…è¡Œè¨˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç­†è€…ãŒè¨ªã‚ŒãŸã¨è€ƒãˆã‚‰ã‚Œã‚‹éƒ½é“åºœçœŒã‚’1ã¤ã ã‘ç­”ãˆã¦ãã ã•ã„ï¼\n\n{visited_places_text}"}]
    try:
        response = openai.ChatCompletion.create(model='gpt-3.5-turbo', messages=messages, temperature=0.2)
        return response.choices[0].message.content.strip()
    except: return "æ—¥æœ¬"

def analyze_emotion(text):
    if not text or not text.strip(): return 0.5
    print(f"ğŸ§  Analyzing emotion for: '{text[:40]}...'")
    prompt = f'ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€æ—…è¡Œä¸­ã®ã‚ã‚‹å ´æ‰€ã§ã®çµŒé¨“ã‚’è¨˜è¿°ã—ãŸã‚‚ã®ã§ã™ã€‚ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚’åˆ†æã—ã€ã€Œãƒã‚¸ãƒ†ã‚£ãƒ–ã€ã€Œãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã€ã€Œãƒã‚¬ãƒ†ã‚£ãƒ–ã€ã®3æ®µéšã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚ãã—ã¦ã€ãã®æ„Ÿæƒ…ã®åº¦åˆã„ã‚’0.0ï¼ˆéå¸¸ã«ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‹ã‚‰1.0ï¼ˆéå¸¸ã«ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼‰ã®é–“ã®æ•°å€¤ï¼ˆã‚¹ã‚³ã‚¢ï¼‰ã§è¡¨ç¾ã—ã¦ãã ã•ã„ã€‚ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ãªæ„Ÿæƒ…ã¯0.5ã¨ã—ã¾ã™ã€‚å‡ºåŠ›ã¯å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚\n{{"sentiment": "ï¼ˆã“ã“ã«è©•ä¾¡ï¼‰", "score": ï¼ˆã“ã“ã«ã‚¹ã‚³ã‚¢ï¼‰}}\n\nãƒ†ã‚­ã‚¹ãƒˆï¼šã€Œ{text}ã€'
    try:
        response = openai.ChatCompletion.create(model="gpt-4o", messages=[{"role": "system", "content": "ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ„Ÿæƒ…ã‚’èª­ã¿å–ã‚Šã€0.0ã‹ã‚‰1.0ã®æ•°å€¤ã§å®šé‡åŒ–ã™ã‚‹å„ªç§€ãªæ„Ÿæƒ…åˆ†æã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"}, {"role": "user", "content": prompt}], temperature=0.1, response_format={"type": "json_object"})
        result = json.loads(response.choices[0].message.content)
        return float(result.get("score", 0.5))
    except: return 0.5

### â˜…â˜…â˜… æ©Ÿèƒ½è¿½åŠ : ã‚¿ã‚°æŠ½å‡ºé–¢æ•° â˜…â˜…â˜…
def extract_tags(text, tag_list, tag_category):
    """GPTã‚’ä½¿ã£ã¦ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸãƒªã‚¹ãƒˆã®ã‚¿ã‚°ã‚’æŠ½å‡ºã™ã‚‹"""
    if not text or not text.strip():
        return []

    print(f"ğŸ·ï¸ Extracting '{tag_category}' tags for: '{text[:40]}...'")
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€æ—…è¡Œä¸­ã®ã‚ã‚‹å ´æ‰€ã§ã®çµŒé¨“ã‚’è¨˜è¿°ã—ãŸã‚‚ã®ã§ã™ã€‚
    æç¤ºã•ã‚ŒãŸã€Œ{tag_category}ã€ã®ã‚¿ã‚°ãƒªã‚¹ãƒˆã®ä¸­ã‹ã‚‰ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã«æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ã‚¿ã‚°ã‚’ã™ã¹ã¦é¸æŠã—ã¦ãã ã•ã„ã€‚
    é–¢é€£æ€§ã®é«˜ã„ã‚¿ã‚°ãŒä¸€ã¤ã‚‚ãªã‘ã‚Œã°ã€ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

    å‡ºåŠ›ã¯å¿…ãšJSONå½¢å¼ã®ã‚¿ã‚°åã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚
    ä¾‹: ["ãƒã‚¹", "å¾’æ­©"]

    ã€Œ{tag_category}ã€ã‚¿ã‚°ãƒªã‚¹ãƒˆ:
    {tag_list}

    ãƒ†ã‚­ã‚¹ãƒˆ:
    ã€Œ{text}ã€
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": f"ã‚ãªãŸã¯ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’åˆ†æã—ã€ä¸ãˆã‚‰ã‚ŒãŸãƒªã‚¹ãƒˆã‹ã‚‰é–¢é€£ã™ã‚‹ã€Œ{tag_category}ã€ã‚¿ã‚°ã‚’æ­£ç¢ºã«æŠ½å‡ºã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        # GPTã®å¿œç­”ãŒ {"tags": ["..."]} ã®ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’æƒ³å®š
        result = json.loads(response.choices[0].message.content)
        # "tags"ã‚­ãƒ¼ã‚„ä»–ã®å¯èƒ½æ€§ã®ã‚ã‚‹ã‚­ãƒ¼ã‚’æ¢ã™
        tags = []
        for key in result:
            if isinstance(result[key], list):
                tags = result[key]
                break
        return tags
    except Exception as e:
        print(f"[ERROR] ã‚¿ã‚°æŠ½å‡ºä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

### â˜…â˜…â˜… æ©Ÿèƒ½è¿½åŠ : ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã«ã‚¿ã‚°è¡¨ç¤ºæ©Ÿèƒ½ã‚’è¿½åŠ  â˜…â˜…â˜…
def map_emotion_and_routes(travels_data, output_html):
    """æ„Ÿæƒ…ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã¨è¨ªå•çµŒè·¯ã‚’ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ‡ã‚Šæ›¿ãˆå¯èƒ½ãªåœ°å›³ã¨ã—ã¦ç”Ÿæˆã™ã‚‹"""
    if not travels_data: print("[ERROR] åœ°å›³ã«æç”»ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return
    try:
        first_travel = travels_data[0]['places'][0]
        start_coords = (first_travel['latitude'], first_travel['longitude'])
        m = folium.Map(location=start_coords, zoom_start=10)
    except (IndexError, KeyError):
        m = folium.Map(location=[35.6812, 139.7671], zoom_start=10)
    
    heatmap_data = []
    for travel in travels_data:
        file_num, places, color = travel["file_num"], travel["places"], travel["color"]
        route_group = folium.FeatureGroup(name=f"æ—…è¡Œè¨˜ãƒ«ãƒ¼ãƒˆ: {file_num}", show=True)
        locations = []
        for place_data in places:
            coords = (place_data['latitude'], place_data['longitude'])
            popup_html = f"<b>{place_data['place']}</b> (æ—…è¡Œè¨˜: {file_num})<br>"
            
            # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢è¡¨ç¤º
            popup_html += f"<b>æ„Ÿæƒ…ã‚¹ã‚³ã‚¢: {place_data.get('emotion_score', 0.5):.2f}</b><br>"
            
            # ã‚¿ã‚°è¡¨ç¤º
            tags = place_data.get('tags', [])
            if tags:
                popup_html += f"<hr style='margin: 3px 0;'>"
                popup_html += "<b>ã‚¿ã‚°:</b><br>"
                tag_html = ""
                for tag in tags:
                    tag_style = "display:inline-block; background-color:#E0E0E0; color:#333; padding:2px 6px; margin:2px; border-radius:4px; font-size:12px;"
                    tag_html += f"<span style='{tag_style}'>{tag}</span>"
                popup_html += tag_html
            
            # æ¨å®šç†ç”±è¡¨ç¤º
            if 'reasoning' in place_data and place_data['reasoning']:
                popup_html += f"<hr style='margin: 3px 0;'>"
                popup_html += f"<b>æ¨å®šç†ç”±:</b><br>{place_data['reasoning']}<br>"
            
            # ä½“é¨“è¡¨ç¤º
            popup_html += f"<hr style='margin: 3px 0;'>"
            popup_html += f"<b>ä½“é¨“:</b><br>{place_data['experience']}"

            folium.Marker(
                location=coords, popup=folium.Popup(popup_html, max_width=350),
                tooltip=f"{place_data['place']} ({file_num})", icon=folium.Icon(color=color, icon="info-sign")
            ).add_to(route_group)
            
            locations.append(coords)
            heatmap_data.append([coords[0], coords[1], place_data.get('emotion_score', 0.5)])
        
        if len(locations) > 1:
            folium.PolyLine(locations, color=color, weight=5, opacity=0.7).add_to(route_group)
        route_group.add_to(m)

    if heatmap_data:
        heatmap_layer = folium.FeatureGroup(name="æ„Ÿæƒ…ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", show=False)
        HeatMap(heatmap_data).add_to(heatmap_layer)
        heatmap_layer.add_to(m)
    folium.LayerControl().add_to(m)
    m.save(output_html)
    print(f"\nğŸŒ æ„Ÿæƒ…ãƒ»ã‚¿ã‚°åˆ†æä»˜ãã®åœ°å›³ã‚’ {output_html} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

### â˜…â˜…â˜… æ©Ÿèƒ½è¿½åŠ : ãƒ¡ã‚¤ãƒ³å‡¦ç†ã«ã‚¿ã‚°æŠ½å‡ºã‚’è¿½åŠ  â˜…â˜…â˜…
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    input_file_path = input('ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ãŒè¨˜è¼‰ã•ã‚ŒãŸ.txtãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ')
    try:
        with open(input_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        file_nums_raw = content.strip().split(',')
        file_nums = [num.strip() for num in file_nums_raw if num.strip()] 
        if not file_nums: print("[ERROR] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"); return
        print(f"INFO: ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(file_nums)} ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ç•ªå·ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except FileNotFoundError: print(f"[ERROR] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_file_path}"); return
    except Exception as e: print(f"[ERROR] ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return

    all_travels_data = []
    for i, file_num in enumerate(file_nums):
        path_journal = f'{directory}{file_num}.tra.json'
        print(f"\n{'='*20} [{file_num}] ã®å‡¦ç†ã‚’é–‹å§‹ {'='*20}")
        if not os.path.exists(path_journal): print(f"[WARNING] ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path_journal}"); continue
        try:
            with open(path_journal, "r", encoding="utf-8") as f: travel_data = json.load(f)
        except: print(f"[ERROR] JSONèª­ã¿è¾¼ã¿å¤±æ•—"); continue
        texts = [];
        for entry in travel_data: texts.extend(entry['text'])
        full_text = " ".join(texts)
        if not full_text.strip(): print(f"[WARNING] æ—…è¡Œè¨˜ {file_num} ã«ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); continue
        
        region_hint = get_visit_hint(full_text)
        extracted_places = extract_places(full_text, region_hint)
        if not extracted_places: print(f"[WARNING] æ—…è¡Œè¨˜ {file_num} ã‹ã‚‰è¨ªå•åœ°ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"); continue

        places_with_coords = []
        for place_data in extracted_places:
            place_name = place_data['place']
            coords = geocode_place(place_name, region_hint)
            if not coords:
                coords = (place_data['latitude'], place_data['longitude'])
                if coords[0] == 0.0 and coords[1] == 0.0: coords = None
            if not coords:
                coords = geocode_gsi(place_name)
            if coords:
                place_data['latitude'] = coords[0]
                place_data['longitude'] = coords[1]
                places_with_coords.append(place_data)
            else:
                print(f"[!] å…¨ã¦ã®ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¤±æ•—ã—ã¾ã—ãŸ: {place_name}")

        # å ´æ‰€ã”ã¨ã«ã¾ã¨ã‚ãŸexperienceã‹ã‚‰æ„Ÿæƒ…ã¨ã‚¿ã‚°ã‚’æŠ½å‡º
        grouped_experiences = defaultdict(list)
        for p in places_with_coords: grouped_experiences[p['place']].append(p['experience'])
        
        place_analysis_results = {}
        for place, experiences in grouped_experiences.items():
            combined_experience = " ".join(experiences)
            # æ„Ÿæƒ…åˆ†æ
            score = analyze_emotion(combined_experience)
            # ã‚¿ã‚°æŠ½å‡º
            move_tags = extract_tags(combined_experience, MOVE_TAGS, "ç§»å‹•æ‰‹æ®µ")
            action_tags = extract_tags(combined_experience, ACTION_TAGS, "è¡Œå‹•")
            all_tags = move_tags + action_tags
            
            place_analysis_results[place] = {"score": score, "tags": all_tags}

        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨ã‚¿ã‚°ã‚’å…ƒã®ãƒ‡ãƒ¼ã‚¿ã«ä»˜ä¸
        for p in places_with_coords:
            analysis = place_analysis_results.get(p['place'], {"score": 0.5, "tags": []})
            p['emotion_score'] = analysis['score']
            p['tags'] = analysis['tags']
        
        print(f"ğŸ“Œ å‡¦ç†å®Œäº† ({file_num}): {len(places_with_coords)}ä»¶ã®è¨ªå•åœ°ã‚’åœ°å›³ã«è¿½åŠ ã—ã¾ã™ã€‚")
        all_travels_data.append({
            "file_num": file_num, "places": places_with_coords,
            "color": COLORS[i % len(COLORS)], "region_hint": region_hint 
        })

    if all_travels_data:
        if len(file_nums) >= 4:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_filename = f"{base_name}{timestamp}{extension}"
        else:
            output_filename = f"{base_name}{'_'.join(file_nums)}{extension}"
        map_emotion_and_routes(all_travels_data, output_filename)
    else:
        print("\nåœ°å›³ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == '__main__':
    main()